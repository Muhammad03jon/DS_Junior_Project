import streamlit as st
import pandas as pd
import numpy as np
from gensim.models.doc2vec import Doc2Vec
from sklearn.metrics.pairwise import cosine_similarity
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import string

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title="NextPodcast ‚Äî –†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–æ–¥–∫–∞—Å—Ç–æ–≤", page_icon="üéß", layout="wide")

# –°—Ç–∏–ª–∏
st.markdown("""
    <style>
        .main { padding: 2rem; font-family: 'Open Sans', sans-serif; }
        h1, h2, h3, h4 { color: #4A4A4A; }
        .stButton>button {
            width: 100%; background: linear-gradient(90deg, #6C63FF, #A084DC);
            color: white; border: none; padding: 0.6rem; border-radius: 0.5rem;
            font-weight: bold; transition: 0.3s ease;
        }
        .stButton>button:hover {
            background: linear-gradient(90deg, #4C47E3, #6F5BB5); transform: scale(1.05);
        }
        .recommendation-card {
            padding: 1rem; border-radius: 1rem; background: #F4F4FB;
            margin: 1rem 0; border-left: 5px solid #6C63FF;
            box-shadow: 0 4px 8px rgba(0,0,0,0.05); transition: 0.3s ease;
        }
        .recommendation-card:hover {
            transform: translateY(-4px); box-shadow: 0 6px 12px rgba(0,0,0,0.1);
        }
    </style>
""", unsafe_allow_html=True)

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
nltk.download('punkt')
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))
punctuation = set(string.punctuation)

def preprocess_text(text):
    tokens = word_tokenize(text.lower())
    return [word for word in tokens if word.isalpha() and word not in stop_words and word not in punctuation]

@st.cache_data
def load_podcast_data():
    url = "https://raw.githubusercontent.com/Muhammad03jon/DS_Junior_Project/refs/heads/master/data_for_podcasts.csv"
    try:
        df = pd.read_csv(url)
        df['episodeName'] = df['episodeName'].str.strip()
        df['clean_description'] = df['clean_description'].str.strip()
        return df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return pd.DataFrame()

@st.cache_resource
def load_model():
    return Doc2Vec.load("podcast_doc2vec.model")

def get_podcast_vector(model, description):
    return model.infer_vector(preprocess_text(description))

def recommend_by_doc2vec(model, df, episode_name, top_n=5):
    if episode_name not in df['episodeName'].values:
        return []

    target_desc = df[df['episodeName'] == episode_name]['clean_description'].values[0]
    target_vec = get_podcast_vector(model, target_desc)

    all_vectors = np.array([get_podcast_vector(model, desc) for desc in df['clean_description']])
    similarities = cosine_similarity([target_vec], all_vectors)[0]
    similar_indices = similarities.argsort()[-top_n-1:-1][::-1]

    results = df.iloc[similar_indices].copy()
    results['similarity'] = similarities[similar_indices].round(2)
    return results[['episodeName', 'rank', 'show.publisher', 'show.total_episodes', 'explicit', 'duration_min', 'similarity']]

def main():
    st.title("üéß NextPodcast ‚Äî –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø–æ–¥–∫–∞—Å—Ç–∞–º")

    df = load_podcast_data()
    if df.empty:
        return

    model = load_model()

    st.sidebar.header("üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
    episode_name = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —ç–ø–∏–∑–æ–¥:", options=df['episodeName'].dropna().unique())
    n_recs = st.sidebar.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:", 1, 10, 5)
    show_recs = st.sidebar.button("üîç –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")

    if not show_recs:
        st.subheader("üî• –¢–æ–ø-10 –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –ø–æ–¥–∫–∞—Å—Ç–æ–≤")
        top10 = df.nlargest(10, 'rank')
        cols = st.columns(2)
        for i, (_, pod) in enumerate(top10.iterrows()):
            with cols[i % 2]:
                st.markdown(f"""
                    <div class="recommendation-card">
                        <h4>{pod['episodeName']}</h4>
                        <p><strong>–†–µ–π—Ç–∏–Ω–≥:</strong> {pod['rank']}</p>
                        <p><strong>–ò–∑–¥–∞—Ç–µ–ª—å:</strong> {pod.get('show.publisher', '‚Äî')}</p>
                        <p><strong>–≠–ø–∏–∑–æ–¥–æ–≤:</strong> {pod.get('show.total_episodes', '‚Äî')}</p>
                        <p><strong>–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:</strong> {pod.get('duration_min', '‚Äî')} –º–∏–Ω</p>
                        <p><strong>–≠–∫—Å–ø–ª–∏—Ü–∏—Ç–Ω—ã–π:</strong> {pod.get('explicit', '‚Äî')}</p>
                    </div>
                """, unsafe_allow_html=True)
    else:
        st.subheader("üéØ –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥–∫–∞—Å—Ç—ã")
        recommendations = recommend_by_doc2vec(model, df, episode_name, n_recs)
        if recommendations.empty:
            st.warning("–ù–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π.")
        else:
            for i, (_, rec) in enumerate(recommendations.iterrows(), 1):
                st.markdown(f"""
                    <div class="recommendation-card">
                        <h4>{i}. {rec['episodeName']}</h4>
                        <p><strong>–ü–æ—Ö–æ–∂–µ—Å—Ç—å:</strong> {rec['similarity']}</p>
                        <p><strong>–†–µ–π—Ç–∏–Ω–≥:</strong> {rec['rank']}</p>
                        <p><strong>–ò–∑–¥–∞—Ç–µ–ª—å:</strong> {rec['show.publisher']}</p>
                        <p><strong>–≠–ø–∏–∑–æ–¥–æ–≤:</strong> {rec['show.total_episodes']}</p>
                        <p><strong>–≠–∫—Å–ø–ª–∏—Ü–∏—Ç–Ω—ã–π:</strong> {rec['explicit']}</p>
                        <p><strong>–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:</strong> {rec['duration_min']} –º–∏–Ω</p>
                    </div>
                """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
